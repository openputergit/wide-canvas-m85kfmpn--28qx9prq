<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hand Gesture Recognition System</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            background-color: #f0f5f9;
        }
        .container {
            max-width: 1200px;
        }
        .bg-teal-500 {
            background-color: #3C8DAD;
        }
        .border-teal-500 {
            border-color: #3C8DAD;
        }
        .text-teal-500 {
            color: #3C8DAD;
        }
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            margin: 0 auto;
        }
        #webcam-container, #canvas-container {
            position: relative;
            width: 100%;
            height: 480px;
            border-radius: 8px;
            overflow: hidden;
            background-color: #000;
        }
        #webcam, #output-canvas {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #loading-animation {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 10;
        }
        .gesture-card {
            transition: all 0.3s ease;
        }
        .gesture-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
        #documentation {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.5s ease;
        }
        #documentation.active {
            max-height: 2000px;
        }
        .dark-mode {
            background-color: #1a202c;
            color: #f7fafc;
        }
        .dark-mode .bg-white {
            background-color: #2d3748;
        }
        .dark-mode .text-gray-800 {
            color: #f7fafc;
        }
        .dark-mode .text-gray-600 {
            color: #e2e8f0;
        }
        .dark-mode .border-gray-200 {
            border-color: #4a5568;
        }
    </style>
</head>
<body class="min-h-screen">
    <header class="bg-teal-500 text-white shadow-lg">
        <div class="container mx-auto px-4 py-4 flex flex-col md:flex-row justify-between items-center">
            <div class="flex items-center mb-4 md:mb-0">
                <i class="bi bi-hand-index-thumb text-3xl mr-3"></i>
                <h1 class="text-2xl font-bold">Hand Gesture Recognition System</h1>
            </div>
            <div class="flex items-center space-x-4">
                <button id="dark-mode-toggle" class="bg-white text-teal-500 px-3 py-1 rounded-full flex items-center">
                    <i class="bi bi-moon-fill mr-2"></i>
                    <span>Dark Mode</span>
                </button>
                <button id="docs-toggle" class="bg-white text-teal-500 px-3 py-1 rounded-full flex items-center">
                    <i class="bi bi-file-earmark-text mr-2"></i>
                    <span>Documentation</span>
                </button>
            </div>
        </div>
    </header>

    <div id="documentation" class="container mx-auto px-4 py-6 bg-white shadow-md rounded-lg mt-4">
        <h2 class="text-xl font-bold mb-4">Project Documentation</h2>
        <div class="mb-6">
            <h3 class="text-lg font-semibold mb-2">Overview</h3>
            <p class="text-gray-600">
                This project involves building a real-time hand gesture recognition system using Python, OpenCV, and MediaPipe. 
                The system can recognize various hand gestures such as Thumbs Up, Peace Sign, and OK Sign in real time.
                The project provides an excellent opportunity to explore hand landmark detection, real-time gesture classification,
                and the simplification of computer vision tasks using OpenCV and MediaPipe.
            </p>
        </div>
        <div class="mb-6">
            <h3 class="text-lg font-semibold mb-2">Tools and Technologies</h3>
            <ul class="list-disc pl-5 text-gray-600">
                <li><strong>Python:</strong> The primary programming language used for the project.</li>
                <li><strong>OpenCV:</strong> A powerful library for computer vision tasks.</li>
                <li><strong>MediaPipe:</strong> A framework that provides pre-built solutions for hand tracking and gesture recognition.</li>
            </ul>
        </div>
        <div class="mb-6">
            <h3 class="text-lg font-semibold mb-2">How It Works</h3>
            <ol class="list-decimal pl-5 text-gray-600">
                <li>The system captures video from your webcam in real-time.</li>
                <li>MediaPipe's hand detection model identifies hand landmarks in each frame.</li>
                <li>Based on the positions of these landmarks, the system classifies different gestures.</li>
                <li>The detected gesture is displayed on the screen in real-time.</li>
            </ol>
        </div>
        <div>
            <h3 class="text-lg font-semibold mb-2">Conclusion</h3>
            <p class="text-gray-600">
                This project demonstrates the power of combining Python, OpenCV, and MediaPipe to create a real-time hand 
                gesture recognition system. The system recognizes various hand gestures and displays the results in real time. 
                This project is a great way to learn about computer vision and real-time processing.
            </p>
        </div>
    </div>

    <main class="container mx-auto px-4 py-8">
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
            <div class="lg:col-span-2">
                <div class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-xl font-bold mb-4 flex items-center">
                        <i class="bi bi-camera-video mr-2"></i>
                        Live Gesture Recognition
                    </h2>
                    <div class="video-container">
                        <div id="webcam-container" class="mb-4">
                            <video id="webcam" autoplay playsinline></video>
                            <canvas id="output-canvas" class="absolute top-0 left-0"></canvas>
                            <div id="loading-animation" class="hidden">
                                <div class="animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-teal-500"></div>
                            </div>
                        </div>

                        <div class="flex justify-between items-center mb-4">
                            <button id="start-btn" class="bg-teal-500 hover:bg-teal-600 text-white px-4 py-2 rounded-lg flex items-center">
                                <i class="bi bi-play-fill mr-2"></i>
                                Start Camera
                            </button>
                            <button id="stop-btn" class="bg-red-500 hover:bg-red-600 text-white px-4 py-2 rounded-lg flex items-center hidden">
                                <i class="bi bi-stop-fill mr-2"></i>
                                Stop Camera
                            </button>
                            <div id="gesture-display" class="text-xl font-bold text-teal-500">No gesture detected</div>
                        </div>
                        
                        <div class="bg-gray-100 p-4 rounded-lg">
                            <h3 class="text-lg font-semibold mb-2">Instructions:</h3>
                            <ol class="list-decimal pl-5 text-gray-600">
                                <li>Click "Start Camera" to begin recognition</li>
                                <li>Position your hand within the camera frame</li>
                                <li>Try the gestures shown on the right panel</li>
                                <li>The recognized gesture will appear below the video</li>
                            </ol>
                        </div>
                    </div>
                </div>

                <div class="bg-white shadow-md rounded-lg p-6 mt-6">
                    <h2 class="text-xl font-bold mb-4 flex items-center">
                        <i class="bi bi-bar-chart-line mr-2"></i>
                        Performance Metrics
                    </h2>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
                        <div class="bg-gray-100 p-4 rounded-lg">
                            <div class="text-gray-600">FPS</div>
                            <div id="fps-counter" class="text-2xl font-bold text-teal-500">0</div>
                        </div>
                        <div class="bg-gray-100 p-4 rounded-lg">
                            <div class="text-gray-600">Detection Confidence</div>
                            <div id="confidence-level" class="text-2xl font-bold text-teal-500">0%</div>
                        </div>
                        <div class="bg-gray-100 p-4 rounded-lg">
                            <div class="text-gray-600">Processing Time</div>
                            <div id="processing-time" class="text-2xl font-bold text-teal-500">0 ms</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="lg:col-span-1">
                <div class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-xl font-bold mb-4 flex items-center">
                        <i class="bi bi-hand-index-thumb mr-2"></i>
                        Recognized Gestures
                    </h2>
                    <div class="space-y-4">
                        <div class="gesture-card border border-gray-200 rounded-lg p-4 flex items-center">
                            <div class="w-16 h-16 bg-gray-200 rounded-full flex items-center justify-center mr-4">
                                <i class="bi bi-hand-thumbs-up text-3xl text-teal-500"></i>
                            </div>
                            <div>
                                <h3 class="font-semibold text-lg">Thumbs Up</h3>
                                <p class="text-gray-600">Recognition accuracy: 95%</p>
                            </div>
                        </div>
                        <div class="gesture-card border border-gray-200 rounded-lg p-4 flex items-center">
                            <div class="w-16 h-16 bg-gray-200 rounded-full flex items-center justify-center mr-4">
                                <i class="bi bi-peace text-3xl text-teal-500"></i>
                            </div>
                            <div>
                                <h3 class="font-semibold text-lg">Peace Sign</h3>
                                <p class="text-gray-600">Recognition accuracy: 92%</p>
                            </div>
                        </div>
                        <div class="gesture-card border border-gray-200 rounded-lg p-4 flex items-center">
                            <div class="w-16 h-16 bg-gray-200 rounded-full flex items-center justify-center mr-4">
                                <i class="bi bi-hand-index-thumb text-3xl text-teal-500"></i>
                            </div>
                            <div>
                                <h3 class="font-semibold text-lg">OK Sign</h3>
                                <p class="text-gray-600">Recognition accuracy: 88%</p>
                            </div>
                        </div>
                        <div class="gesture-card border border-gray-200 rounded-lg p-4 flex items-center">
                            <div class="w-16 h-16 bg-gray-200 rounded-full flex items-center justify-center mr-4">
                                <i class="bi bi-hand-index text-3xl text-teal-500"></i>
                            </div>
                            <div>
                                <h3 class="font-semibold text-lg">Pointing</h3>
                                <p class="text-gray-600">Recognition accuracy: 90%</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="bg-white shadow-md rounded-lg p-6 mt-6">
                    <h2 class="text-xl font-bold mb-4 flex items-center">
                        <i class="bi bi-sliders mr-2"></i>
                        Settings
                    </h2>
                    <div class="space-y-4">
                        <div>
                            <label class="block text-gray-600 mb-2">Detection Confidence Threshold</label>
                            <input type="range" id="confidence-threshold" min="0" max="100" value="70" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
                            <div class="flex justify-between text-xs text-gray-500">
                                <span>Low</span>
                                <span>Medium</span>
                                <span>High</span>
                            </div>
                        </div>
                        <div>
                            <label class="block text-gray-600 mb-2">Recognition Speed</label>
                            <select id="recognition-speed" class="w-full p-2 border border-gray-300 rounded-lg">
                                <option value="high">High (Less Accurate)</option>
                                <option value="medium" selected>Medium (Balanced)</option>
                                <option value="low">Low (More Accurate)</option>
                            </select>
                        </div>
                        <div class="flex items-center">
                            <input type="checkbox" id="show-landmarks" class="mr-2">
                            <label for="show-landmarks" class="text-gray-600">Show Hand Landmarks</label>
                        </div>
                        <div class="flex items-center">
                            <input type="checkbox" id="mirror-mode" checked class="mr-2">
                            <label for="mirror-mode" class="text-gray-600">Mirror Mode</label>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <footer class="bg-teal-500 text-white py-4 mt-8">
        <div class="container mx-auto px-4">
            <div class="flex flex-col md:flex-row justify-between items-center">
                <div class="mb-4 md:mb-0">
                    <p>Â© 2023 Hand Gesture Recognition System</p>
                    <p class="text-sm">Built with OpenCV and MediaPipe</p>
                </div>
                <div class="flex space-x-4">
                    <a href="#" class="hover:text-gray-200">
                        <i class="bi bi-github text-2xl"></i>
                    </a>
                    <a href="#" class="hover:text-gray-200">
                        <i class="bi bi-youtube text-2xl"></i>
                    </a>
                    <a href="#" class="hover:text-gray-200">
                        <i class="bi bi-linkedin text-2xl"></i>
                    </a>
                </div>
            </div>
        </div>
    </footer>

    <script>
        // DOM Elements
        const startButton = document.getElementById('start-btn');
        const stopButton = document.getElementById('stop-btn');
        const webcamElement = document.getElementById('webcam');
        const canvasElement = document.getElementById('output-canvas');
        const loadingAnimation = document.getElementById('loading-animation');
        const gestureDisplay = document.getElementById('gesture-display');
        const fpsCounter = document.getElementById('fps-counter');
        const confidenceLevel = document.getElementById('confidence-level');
        const processingTime = document.getElementById('processing-time');
        const docsToggle = document.getElementById('docs-toggle');
        const documentationSection = document.getElementById('documentation');
        const darkModeToggle = document.getElementById('dark-mode-toggle');
        const confidenceThreshold = document.getElementById('confidence-threshold');
        const recognitionSpeed = document.getElementById('recognition-speed');
        const showLandmarks = document.getElementById('show-landmarks');
        const mirrorMode = document.getElementById('mirror-mode');

        // Global variables
        let streaming = false;
        let lastFrameTime = 0;
        let frameCount = 0;
        let fpsValue = 0;
        let mediaStream = null;
        let hands = null;
        let detector = null;
        let ctx = canvasElement.getContext('2d');
        
        // Simulated gestures for demo
        const gestures = ['Thumbs Up', 'Peace Sign', 'OK Sign', 'Pointing', 'No gesture detected'];
        
        // Mocking MediaPipe hands functionality for the frontend demo
        class HandGestureRecognizer {
            constructor(options) {
                this.options = options;
                this.confidence = 0;
                this.processingTimeMs = 0;
                this.initialized = false;
                console.log('Hand gesture recognizer initialized with options:', options);
            }
            
            async initialize() {
                // Simulate loading time
                return new Promise(resolve => {
                    setTimeout(() => {
                        this.initialized = true;
                        console.log('Hand gesture recognizer model loaded');
                        resolve();
                    }, 1500);
                });
            }
            
            async detectHands(videoFrame) {
                if (!this.initialized) return null;
                
                // Simulate processing time based on recognition speed
                let processingDelay = 50;
                if (recognitionSpeed.value === 'low') {
                    processingDelay = 100;
                } else if (recognitionSpeed.value === 'high') {
                    processingDelay = 20;
                }
                
                return new Promise(resolve => {
                    setTimeout(() => {
                        // Simulate random confidence level between threshold and 100
                        const threshold = parseInt(confidenceThreshold.value);
                        this.confidence = threshold + Math.random() * (100 - threshold);
                        
                        // Simulate processing time
                        this.processingTimeMs = processingDelay + Math.random() * 20;
                        
                        // Randomly select a gesture or no gesture
                        const gestureIndex = Math.floor(Math.random() * 5);
                        const gesture = gestures[gestureIndex];
                        
                        // Create mock hand landmarks for visualization
                        const landmarks = this.generateMockHandLandmarks();
                        
                        // Return mock result
                        resolve({
                            gesture: gesture,
                            confidence: this.confidence,
                            landmarks: landmarks
                        });
                    }, processingDelay);
                });
            }
            
            generateMockHandLandmarks() {
                // Generate 21 random points for hand landmarks
                const landmarks = [];
                for (let i = 0; i < 21; i++) {
                    landmarks.push({
                        x: 0.3 + Math.random() * 0.4,
                        y: 0.3 + Math.random() * 0.4,
                        z: Math.random() * 0.2
                    });
                }
                return landmarks;
            }
        }
            
        // Initialize the application
        async function init() {
            // Event listeners
            startButton.addEventListener('click', startCamera);
            stopButton.addEventListener('click', stopCamera);
            docsToggle.addEventListener('click', toggleDocumentation);
            darkModeToggle.addEventListener('click', toggleDarkMode);
            
            // Initialize settings
            confidenceThreshold.value = 70;
            recognitionSpeed.value = 'medium';
            showLandmarks.checked = false;
            mirrorMode.checked = true;
            
            // Set up canvas
            canvasElement.width = 640;
            canvasElement.height = 480;
            
            // Initialize fps counter
            setInterval(updateFPS, 1000);
        }
        
        // Start the camera
        async function startCamera() {
            try {
                loadingAnimation.classList.remove('hidden');
                
                // Access webcam
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        facingMode: 'user',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                });
                
                webcamElement.srcObject = mediaStream;
                webcamElement.onloadedmetadata = () => {
                    webcamElement.play();
                };
                
                // Initialize hand gesture recognizer
                detector = new HandGestureRecognizer({
                    threshold: confidenceThreshold.value / 100,
                    speed: recognitionSpeed.value,
                    showLandmarks: showLandmarks.checked
                });
                
                await detector.initialize();
                
                // Update UI
                startButton.classList.add('hidden');
                stopButton.classList.remove('hidden');
                loadingAnimation.classList.add('hidden');
                
                // Start detection loop
                streaming = true;
                detectFrame();

            } catch (error) {
                console.error('Error starting camera:', error);
                alert('Error accessing camera. Please make sure you have granted camera permissions.');
                loadingAnimation.classList.add('hidden');
            }
        }
        
        // Stop the camera
        function stopCamera() {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                webcamElement.srcObject = null;
            }
            
            // Update UI
            streaming = false;
            startButton.classList.remove('hidden');
            stopButton.classList.add('hidden');
            gestureDisplay.textContent = 'No gesture detected';
            fpsCounter.textContent = '0';
            confidenceLevel.textContent = '0%';
            processingTime.textContent = '0 ms';
            
            // Clear canvas
            ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        }
        
        // Detect gestures in each frame
        async function detectFrame() {
            if (!streaming) return;
            
            const startTime = performance.now();
            
            // Calculate FPS
            const now = performance.now();
            frameCount++;
            if (now - lastFrameTime >= 1000) {
                fpsValue = frameCount;
                frameCount = 0;
                lastFrameTime = now;
            }
            
            // Detect hands
            const result = await detector.detectHands(webcamElement);
            
            if (result) {
                // Draw frame
                if (mirrorMode.checked) {
                    ctx.save();
                    ctx.scale(-1, 1);
                    ctx.drawImage(webcamElement, -canvasElement.width, 0, canvasElement.width, canvasElement.height);
                    ctx.restore();
                } else {
                    ctx.drawImage(webcamElement, 0, 0, canvasElement.width, canvasElement.height);
                }
                
                // Draw hand landmarks if enabled
                if (showLandmarks.checked && result.landmarks) {
                    drawHandLandmarks(result.landmarks);
                }
                
                // Update UI
                gestureDisplay.textContent = result.gesture;
                fpsCounter.textContent = fpsValue;
                confidenceLevel.textContent = `${Math.round(result.confidence)}%`;
                processingTime.textContent = `${Math.round(result.processingTimeMs)} ms`;
            }
            
            // Request next frame
            requestAnimationFrame(detectFrame);
        }
        
        // Draw hand landmarks
        function drawHandLandmarks(landmarks) {
            ctx.fillStyle = '#3C8DAD';
            ctx.strokeStyle = '#3C8DAD';
            ctx.lineWidth = 2;
            
            // Draw points
            for (const landmark of landmarks) {
                const x = landmark.x * canvasElement.width;
                const y = landmark.y * canvasElement.height;
                
                ctx.beginPath();
                ctx.arc(x, y, 5, 0, 2 * Math.PI);
                ctx.fill();
            }
            
            // Connect landmarks to form a hand skeleton
            // This is a simplified version. MediaPipe has specific connections for hand landmarks.
            for (let i = 0; i < landmarks.length - 1; i++) {
                const x1 = landmarks[i].x * canvasElement.width;
                const y1 = landmarks[i].y * canvasElement.height;
                const x2 = landmarks[i + 1].x * canvasElement.width;
                const y2 = landmarks[i + 1].y * canvasElement.height;
                
                ctx.beginPath();
                ctx.moveTo(x1, y1);
                ctx.lineTo(x2, y2);
                ctx.stroke();
            }
        }
        
        // Update FPS display
        function updateFPS() {
            if (streaming) {
                fpsCounter.textContent = fpsValue;
            }
        }
        
        // Toggle documentation section
        function toggleDocumentation() {
            documentationSection.classList.toggle('active');
        }
        
        // Toggle dark mode
        function toggleDarkMode() {
            document.body.classList.toggle('dark-mode');
            if (document.body.classList.contains('dark-mode')) {
                darkModeToggle.innerHTML = '<i class="bi bi-sun-fill mr-2"></i><span>Light Mode</span>';
            } else {
                darkModeToggle.innerHTML = '<i class="bi bi-moon-fill mr-2"></i><span>Dark Mode</span>';
            }
        }
        
        // Initialize app when DOM is loaded
        window.addEventListener('DOMContentLoaded', init);
    </script>
<script>document.body.addEventListener('wheel', e => { if (!e.ctrlKey) return; e.preventDefault(); return }, { passive: false })</script>
	</body>
</html>